{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_coref_md'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d01640bb3d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# import MySQLdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0men_coref_md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'en_coref_md'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# import MySQLdb\n",
    "import en_coref_md\n",
    "import sys\n",
    "\n",
    "nlp = en_coref_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_splitter(text):\n",
    "    lines_in_article = [s.strip() for s in text.splitlines()]\n",
    "    return lines_in_article\n",
    "\n",
    "def print_lines(lines):\n",
    "    for elem in lines:\n",
    "        print elem\n",
    "        print \"------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding annotator tokenize\n",
      "Adding annotator ssplit\n",
      "Adding annotator pos\n",
      "Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [0.7 sec].\n",
      "Adding annotator lemma\n",
      "Adding annotator depparse\n",
      "Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "PreComputed 99996, Elapsed Time: 12.552 (s)\n",
      "Initializing dependency parser ... done [14.0 sec].\n",
      "Adding annotator natlog\n",
      "Adding annotator openie\n",
      "Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0110 seconds]\n",
      "Processing from stdin. Enter one sentence per line.\n",
      "No extractions in: Milo Blah Blah\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from nltk import ngrams\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "fw = open(\"tmpout\", \"wb\")\n",
    "fr = open(\"tmpout\", \"r\")\n",
    "\n",
    "proc = subprocess.Popen(['java', \"-mx8g\", \"-cp\", \"/Users/kumar.jitender/Downloads/stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0.jar:/Users/kumar.jitender/Downloads/stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-models.jar:/Users/kumar.jitender/Downloads/stanford-corenlp-full-2017-06-09/CoreNLP-to-HTML.xsl:slf4j-api.jar:/Users/kumar.jitender/Downloads/stanford-corenlp-full-2017-06-09/slf4j-simple.jar\", \"edu.stanford.nlp.naturalli.OpenIE\",  \"-threads\",  \"8\", \"-ignore_affinity\", \"true\",  \"-ssplit.newlineIsSentenceBreak\", \"always\", \"-format\", \"ollie\"], stdout=fw, stderr=fw, stdin=subprocess.PIPE)\n",
    "\n",
    "proc.stdin.write(\"Milo Blah Blah\\n\")\n",
    "proc.stdin.flush()\n",
    "\n",
    "# Waiting for the model to load properly\n",
    "time.sleep(20)\n",
    "# Discarding initial Output\n",
    "print fr.read()\n",
    "\n",
    "def parse_oie_op(line):\n",
    "    if line.find(':') !=-1:\n",
    "        rel_substring = line[line.find(':') + 3:]\n",
    "        if rel_substring.find(';') != -1:\n",
    "            e1 = rel_substring[:rel_substring.find(';')]\n",
    "            rel_substring = rel_substring[rel_substring.find(';')+2:]\n",
    "            if rel_substring.find(';') != -1:\n",
    "                rel = rel_substring[:rel_substring.find(';')]\n",
    "                rel_substring = rel_substring[rel_substring.find(';')+2:]            \n",
    "                if rel_substring.find(')') != -1:\n",
    "                    e2 = rel_substring[:rel_substring.find(')')]\n",
    "                    return (e1, rel, e2)\n",
    "                else:\n",
    "                    raise ValueError(line)\n",
    "            else:\n",
    "                raise ValueError(line)\n",
    "        else:\n",
    "            raise ValueError(line)\n",
    "        \n",
    "\n",
    "def extract_relations(sentence):\n",
    "    no_of_tokens = len(nltk.word_tokenize(sentence))\n",
    "    myset=set()\n",
    "    for iter in range(max(4, no_of_tokens-5), no_of_tokens+1):\n",
    "        sixgrams = ngrams(sentence.split(), iter)\n",
    "        new_list = [' '.join(words) for words in sixgrams] \n",
    "        for gram in new_list:\n",
    "            proc.stdin.write( gram + \"\\n\")\n",
    "            proc.stdin.flush()\n",
    "        \n",
    "    time.sleep(10)\n",
    "    for line in fr.read().splitlines():\n",
    "        if 'No extractions in' not in line:\n",
    "            myset.add(parse_oie_op(line))\n",
    "    return myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pprint\n",
    "from nltk import Tree\n",
    "\n",
    "# patterns = \"\"\"\n",
    "#     NP: {<JJ>*<NN*>+}\n",
    "#     {<JJ>*<NN*><CC>*<NN*>+}\n",
    "#     \"\"\"\n",
    "\n",
    "patterns = \"\"\"\n",
    "    NP:    {<DT><WP><VBP>*<RB>*<VBN><IN><NN>}\n",
    "           {<NN|NNS|NNP|NNPS><IN>*<NN|NNS|NNP|NNPS>+}\n",
    "           {<JJ|JJR|JJS>*<NN|NNS|NNP|NNPS><CC>*<NN|NNS|NNP|NNPS>+}\n",
    "           {<JJ|JJR|JJS>*<NN|NNS|NNP|NNPS>+}\n",
    "           \n",
    "    \"\"\"\n",
    "\n",
    "NPChunker = nltk.RegexpParser(patterns)\n",
    "\n",
    "def prepare_text(input):\n",
    "    sentences = nltk.sent_tokenize(input)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    sentences = [NPChunker.parse(sent) for sent in sentences]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def parsed_text_to_NP(sentences):\n",
    "    nps = []\n",
    "    for sent in sentences:\n",
    "        tree = NPChunker.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'NP':\n",
    "                t = subtree\n",
    "                t = ' '.join(word for word, tag in t.leaves())\n",
    "                nps.append(t)\n",
    "    return nps\n",
    "\n",
    "\n",
    "def find_nps(text):\n",
    "    prepared = prepare_text(text)\n",
    "    return parsed_text_to_NP(prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortSecond(val):\n",
    "    return val[1] \n",
    "\n",
    "def get_coreferences(paragraph):\n",
    "    doc = nlp(unicode(paragraph , 'latin-1'))\n",
    "    lst_replace = []\n",
    "    if doc._.has_coref:\n",
    "        for cluster in doc._.coref_clusters:\n",
    "            for mention in cluster.mentions:\n",
    "                lst_replace.append((mention.start_char, mention.end_char, mention.text, cluster.main.text))\n",
    "\n",
    "    lst_replace.sort(key=sortSecond)        \n",
    "    return lst_replace\n",
    "\n",
    "\n",
    "def get_coref_replacement_dict(coref_list, sentence_start_char, sentence_end_char):\n",
    "    relevant_corefs = {}\n",
    "    for coref in coref_list:\n",
    "        if coref[0] >= sentence_start_char and coref[1] <= sentence_end_char:\n",
    "            relevant_corefs[remove_stopwords(coref[2])] = coref[3]\n",
    "    return relevant_corefs\n",
    "\n",
    "\n",
    "def prcoess_relations(paragraph):\n",
    "\n",
    "    #     get all coreferences in paragraph\n",
    "    coref_list = get_coreferences(paragraph);\n",
    "#     print \"PARAGRAPH\"\n",
    "#     print paragraph\n",
    "#     print \"COREFERENCES\"\n",
    "#     print coref_list\n",
    "    \n",
    "    #     Split sentences here\n",
    "    all_sentences = nltk.sent_tokenize(paragraph)\n",
    "    \n",
    "    sentence_start_char = 0\n",
    "    sentence_end_char = 0\n",
    "    for sentence in all_sentences:\n",
    "        print \"-----------------------------\"\n",
    "        print \"SENTENCE\"\n",
    "        print sentence\n",
    "\n",
    "        sentence_start_char = sentence_end_char\n",
    "        sentence_end_char = sentence_start_char + len(sentence)\n",
    "        \n",
    "        #     Run Relationship extraction on sentence via Stanford NLP\n",
    "        relationships_set = extract_relations(sentence)\n",
    "        print \"ALL RELATIONSHIPS\"\n",
    "        print relationships_set\n",
    "        \n",
    "        #     Figure stopword removed coreference replacements for that sentence\n",
    "        coref_replacement_dict = get_coref_replacement_dict(coref_list, sentence_start_char, sentence_end_char)\n",
    "        print \"COREF REPLACEMENTS\"\n",
    "        print coref_replacement_dict\n",
    "\n",
    "        #     Remove stopwords from relations\n",
    "        relationships_set_stopword_remove = set()\n",
    "        for relation in relationships_set:\n",
    "            if not remove_stopwords(relation[1]):\n",
    "                new_relation = (remove_stopwords(relation[0]), relation[1], remove_stopwords(relation[2]))\n",
    "            else:\n",
    "                new_relation = (remove_stopwords(relation[0]), remove_stopwords(relation[1]), remove_stopwords(relation[2]))\n",
    "            relationships_set_stopword_remove.add(new_relation)\n",
    "\n",
    "        print \"RELATIONSHIPS AFTER REMOVING STOPWORDS\"\n",
    "        print relationships_set_stopword_remove\n",
    "        \n",
    "            \n",
    "        #     Replace coreferences\n",
    "        relationships_set_coref_replace = set()\n",
    "        for relation in relationships_set_stopword_remove:\n",
    "            if relation[0] in coref_replacement_dict:\n",
    "                e1 = coref_replacement_dict[relation[0]]\n",
    "            else:\n",
    "                e1 = relation[0]\n",
    "            if relation[2] in coref_replacement_dict:\n",
    "                e2 = coref_replacement_dict[relation[2]]\n",
    "            else:\n",
    "                e2 = relation[2]\n",
    "            new_relation = (e1, relation[1], e2)\n",
    "            relationships_set_coref_replace.add(new_relation)\n",
    "        \n",
    "        print \"RELATIONSHIPS AFTER CoREF REPLACEMENT\"\n",
    "        print relationships_set_coref_replace\n",
    "        \n",
    "        \n",
    "        #     Figure Nounphrases for that sentence                \n",
    "        noun_phrases = find_nps(sentence)\n",
    "        print \"NOUN PHRASES\"\n",
    "        print noun_phrases\n",
    "        \n",
    "        # Replace corefs in noun_phrases as well\n",
    "        # Noun phrases are already stopword removed, if not, remove\n",
    "        \n",
    "        noun_phrases_coref_filtered = set()\n",
    "        for noun_phrase in noun_phrases:\n",
    "            noun_phrase_temp = remove_stopwords(noun_phrase)\n",
    "            if noun_phrase_temp in coref_replacement_dict:\n",
    "                noun_phrases_coref_filtered.add(coref_replacement_dict[noun_phrase_temp])\n",
    "            else:\n",
    "                noun_phrases_coref_filtered.add(noun_phrase_temp)\n",
    "                            \n",
    "        filtered_relationships_set = set()\n",
    "        #     Filter relations on the NPhrases\n",
    "        for relation in relationships_set_coref_replace:\n",
    "            if relation[0] in noun_phrases_coref_filtered and relation[2] in noun_phrases_coref_filtered:\n",
    "                filtered_relationships_set.add(relation)\n",
    "                \n",
    "        print \"RELATIONSHIPS AFTER NOUN PHRASE FIltering\"\n",
    "        print filtered_relationships_set\n",
    "    return filtered_relationships_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label Pumas shoes', 'firm fan', 'Sophia Websters signature', 'cult status']\n"
     ]
    }
   ],
   "source": [
    "print(find_nps(\"Celebrity-favourite label Pumas shoes already come with a firm fan following but throw in Sophia Websters signature, playful aesthetic and youre guaranteed cult status.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w.lower() not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "        \n",
    "    return ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "SENTENCE\n",
      "Priyanka Chopra is one busy star.\n",
      "ALL RELATIONSHIPS\n",
      "set([('Priyanka Chopra', 'is', 'one busy star'), ('Priyanka Chopra', 'is', 'one busy'), ('Chopra', 'is', 'one star'), ('Chopra', 'is', 'one busy'), ('Priyanka Chopra', 'is', 'one star'), ('Priyanka Chopra', 'is', 'one'), ('Chopra', 'is', 'one busy star')])\n",
      "COREF REPLACEMENTS\n",
      "{u'Priyanka Chopra': u'Priyanka Chopra'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Priyanka Chopra', 'is', 'one busy star'), ('Priyanka Chopra', 'is', 'one busy'), ('Chopra', 'is', 'one star'), ('Chopra', 'is', 'one busy'), ('Priyanka Chopra', 'is', 'one star'), ('Priyanka Chopra', 'is', 'one'), ('Chopra', 'is', 'one busy star')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Priyanka Chopra', 'is', 'one busy star'), (u'Priyanka Chopra', 'is', 'one busy'), ('Chopra', 'is', 'one star'), ('Chopra', 'is', 'one busy'), (u'Priyanka Chopra', 'is', 'one star'), (u'Priyanka Chopra', 'is', 'one'), ('Chopra', 'is', 'one busy star')])\n",
      "NOUN PHRASES\n",
      "['Priyanka Chopra', 'busy star']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "The actor has spent the past few weeks shooting for the new season of Quantico in New York, and as soon as she wrapped up her schedule for the TV series, Chopra was spotted flying out of the Big Apple for a getaway in Dubai.\n",
      "ALL RELATIONSHIPS\n",
      "set([('actor', 'shooting for', 'season'), ('actor', 'shooting for', 'season in New York'), ('actor', 'shooting for', 'new season of Quantico'), ('actor', 'shooting for', 'season of Quantico in New York'), ('Chopra', 'flying out of', 'Big Apple'), ('actor', 'shooting for', 'new season in New York'), ('Chopra', 'flying for', 'getaway in Dubai'), ('actor', 'spent at_time', 'past weeks'), ('new season', 'is in', 'New York'), ('actor', 'spent soon at_time', 'past few weeks'), ('Chopra', 'flying for', 'getaway'), ('actor', 'spent as soon at_time', 'past few weeks'), ('Chopra', 'spent', 'past weeks shooting for new season of Quantico in New York'), ('getaway', 'is in', 'Dubai'), ('Chopra', 'was', 'spotted flying'), ('Chopra', 'spent', 'past few weeks shooting for new season of Quantico in New York'), ('actor', 'shooting for', 'new season of Quantico in New York'), ('spotted', 'flying out', 'Big Apple'), ('actor', 'shooting for', 'new season'), ('actor', 'shooting for', 'season of Quantico'), ('Chopra', 'was', 'spotted'), ('actor', 'spent at_time', 'past few weeks'), ('actor', 'spent as soon at_time', 'past weeks'), ('actor', 'spent soon at_time', 'past weeks')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Priyanka Chopra', u'Chopra': u'Priyanka Chopra', u'actor': u'Priyanka Chopra'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Chopra', 'was', 'spotted'), ('Chopra', 'flying', 'Big Apple'), ('actor', 'shooting', 'new season'), ('actor', 'shooting', 'season New York'), ('spotted', 'flying', 'Big Apple'), ('Chopra', 'flying', 'getaway Dubai'), ('Chopra', 'was', 'spotted flying'), ('getaway', 'is in', 'Dubai'), ('actor', 'shooting', 'new season New York'), ('actor', 'shooting', 'season Quantico'), ('actor', 'shooting', 'season Quantico New York'), ('Chopra', 'flying', 'getaway'), ('Chopra', 'spent', 'past weeks shooting new season Quantico New York'), ('actor', 'shooting', 'new season Quantico New York'), ('actor', 'shooting', 'season'), ('actor', 'shooting', 'new season Quantico'), ('new season', 'is in', 'New York'), ('actor', 'spent soon at_time', 'past weeks'), ('actor', 'spent at_time', 'past weeks')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Priyanka Chopra', 'shooting', 'new season New York'), (u'Priyanka Chopra', 'shooting', 'season Quantico New York'), (u'Priyanka Chopra', 'shooting', 'new season Quantico'), (u'Priyanka Chopra', 'shooting', 'new season'), (u'Priyanka Chopra', 'flying', 'getaway'), (u'Priyanka Chopra', 'shooting', 'season New York'), (u'Priyanka Chopra', 'spent', 'past weeks shooting new season Quantico New York'), (u'Priyanka Chopra', 'spent soon at_time', 'past weeks'), (u'Priyanka Chopra', 'shooting', 'new season Quantico New York'), ('getaway', 'is in', 'Dubai'), (u'Priyanka Chopra', 'flying', 'Big Apple'), (u'Priyanka Chopra', 'spent at_time', 'past weeks'), (u'Priyanka Chopra', 'flying', 'getaway Dubai'), ('spotted', 'flying', 'Big Apple'), (u'Priyanka Chopra', 'shooting', 'season'), ('new season', 'is in', 'New York'), (u'Priyanka Chopra', 'was', 'spotted flying'), (u'Priyanka Chopra', 'was', 'spotted'), (u'Priyanka Chopra', 'shooting', 'season Quantico')])\n",
      "NOUN PHRASES\n",
      "['actor', 'past few weeks', 'season of Quantico', 'New York', 'schedule', 'TV series', 'Chopra', 'Big Apple', 'getaway in Dubai']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'Priyanka Chopra', 'flying', 'Big Apple'), (u'Priyanka Chopra', 'spent at_time', 'past weeks'), (u'Priyanka Chopra', 'shooting', 'season Quantico'), (u'Priyanka Chopra', 'flying', 'getaway Dubai'), (u'Priyanka Chopra', 'spent soon at_time', 'past weeks')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "For her latest travels, Priyanka Chopra kept her look super sleek in skinny jeans, navy blue boots and a cosy black coat.\n",
      "ALL RELATIONSHIPS\n",
      "set([('Priyanka Chopra', 'kept navy boots at_time', 'latest travels'), ('Priyanka Chopra', 'kept', 'navy boots'), ('her latest travels', 'kept', 'navy boots'), ('Priyanka Chopra', 'kept', 'her look sleek in jeans'), ('her latest travels', 'kept', 'coat'), ('her', 'travels', 'Priyanka Chopra'), ('her travels', 'kept', 'her look super sleek in skinny jeans'), ('her travels', 'kept', 'coat'), ('Priyanka Chopra', 'kept', 'her look'), ('her travels', 'kept', 'her look'), ('her latest travels', 'kept', 'cosy coat'), ('Priyanka Chopra', 'kept', 'her look sleek'), ('Priyanka Chopra', 'kept navy boots at_time', 'travels'), ('her travels', 'kept', 'black coat'), ('her travels', 'kept', 'cosy coat'), ('her travels', 'kept', 'her look super sleek'), ('her travels', 'kept', 'her look sleek in skinny jeans'), ('Priyanka Chopra', 'kept navy boots For', 'her latest travels'), ('her travels', 'kept', 'cosy black'), ('her travels', 'kept', 'black'), ('Priyanka Chopra', 'kept', 'black'), ('her latest travels', 'kept', 'her look super sleek in skinny jeans'), ('her latest travels', 'kept', 'cosy black'), ('her latest travels', 'kept', 'black'), ('her travels', 'kept', 'navy blue boots'), ('Priyanka Chopra', 'kept coat For', 'her latest travels'), ('Priyanka Chopra', 'kept', 'her look super sleek in skinny jeans'), ('Priyanka Chopra', 'kept', 'cosy black'), ('Priyanka Chopra', 'kept coat at_time', 'travels'), ('Priyanka Chopra', 'kept coat at_time', 'latest travels'), ('her travels', 'kept', 'her look sleek in jeans'), ('Priyanka Chopra', 'kept', 'cosy black coat'), ('her latest travels', 'kept', 'her look super sleek'), ('her latest travels', 'kept', 'her look sleek'), ('her latest travels', 'kept', 'cosy black coat'), ('Priyanka Chopra', 'kept', 'cosy coat'), ('her travels', 'kept', 'cosy black coat'), ('Priyanka Chopra', 'kept', 'her look super sleek in jeans'), ('Priyanka Chopra', 'kept navy boots For', 'her travels'), ('her latest travels', 'kept', 'her look'), ('her latest travels', 'kept', 'her look sleek in skinny jeans'), ('her travels', 'kept', 'her look sleek'), ('Priyanka Chopra', 'kept', 'her look super sleek'), ('Priyanka Chopra', 'kept coat For', 'her travels'), ('Priyanka Chopra', 'kept', 'navy blue boots'), ('her latest travels', 'kept', 'navy blue boots'), ('Priyanka Chopra', 'kept', 'cosy'), ('Priyanka Chopra', 'kept', 'her look sleek in skinny jeans'), ('her travels', 'kept', 'navy boots'), ('her latest travels', 'kept', 'her look super sleek in jeans'), ('her latest travels', 'kept', 'black coat'), ('her latest travels', 'kept', 'her look sleek in jeans'), ('her travels', 'kept', 'her look super sleek in jeans'), ('Priyanka Chopra', 'kept', 'black coat'), ('Priyanka Chopra', 'kept', 'coat')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Priyanka Chopra', u'Priyanka Chopra': u'Priyanka Chopra'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('travels', 'kept', 'coat'), ('Priyanka Chopra', 'kept', 'navy boots'), ('latest travels', 'kept', 'black'), ('Priyanka Chopra', 'kept navy boots at_time', 'latest travels'), ('latest travels', 'kept', 'look super sleek skinny jeans'), ('Priyanka Chopra', 'kept', 'look super sleek'), ('travels', 'kept', 'look super sleek jeans'), ('Priyanka Chopra', 'kept navy boots', 'latest travels'), ('Priyanka Chopra', 'kept coat', 'travels'), ('latest travels', 'kept', 'look sleek jeans'), ('Priyanka Chopra', 'kept', 'look sleek skinny jeans'), ('Priyanka Chopra', 'kept navy boots at_time', 'travels'), ('Priyanka Chopra', 'kept', 'look sleek jeans'), ('', 'travels', 'Priyanka Chopra'), ('travels', 'kept', 'look super sleek'), ('travels', 'kept', 'black'), ('travels', 'kept', 'cosy black'), ('latest travels', 'kept', 'look super sleek'), ('Priyanka Chopra', 'kept', 'look super sleek skinny jeans'), ('latest travels', 'kept', 'look sleek skinny jeans'), ('travels', 'kept', 'black coat'), ('travels', 'kept', 'look sleek'), ('Priyanka Chopra', 'kept', 'black'), ('latest travels', 'kept', 'navy boots'), ('Priyanka Chopra', 'kept coat', 'latest travels'), ('latest travels', 'kept', 'black coat'), ('travels', 'kept', 'look sleek jeans'), ('Priyanka Chopra', 'kept', 'cosy black'), ('latest travels', 'kept', 'look'), ('travels', 'kept', 'look sleek skinny jeans'), ('Priyanka Chopra', 'kept coat at_time', 'latest travels'), ('Priyanka Chopra', 'kept', 'navy blue boots'), ('Priyanka Chopra', 'kept', 'look sleek'), ('Priyanka Chopra', 'kept', 'cosy black coat'), ('travels', 'kept', 'look'), ('Priyanka Chopra', 'kept', 'coat'), ('latest travels', 'kept', 'look super sleek jeans'), ('travels', 'kept', 'navy blue boots'), ('Priyanka Chopra', 'kept', 'cosy coat'), ('latest travels', 'kept', 'cosy coat'), ('travels', 'kept', 'cosy black coat'), ('travels', 'kept', 'navy boots'), ('Priyanka Chopra', 'kept', 'look super sleek jeans'), ('travels', 'kept', 'look super sleek skinny jeans'), ('latest travels', 'kept', 'coat'), ('latest travels', 'kept', 'cosy black coat'), ('latest travels', 'kept', 'look sleek'), ('Priyanka Chopra', 'kept', 'cosy'), ('Priyanka Chopra', 'kept', 'look'), ('latest travels', 'kept', 'navy blue boots'), ('latest travels', 'kept', 'cosy black'), ('Priyanka Chopra', 'kept coat at_time', 'travels'), ('travels', 'kept', 'cosy coat'), ('Priyanka Chopra', 'kept navy boots', 'travels'), ('Priyanka Chopra', 'kept', 'black coat')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('travels', 'kept', 'coat'), (u'Priyanka Chopra', 'kept', 'navy boots'), ('latest travels', 'kept', 'black'), (u'Priyanka Chopra', 'kept navy boots at_time', 'latest travels'), ('latest travels', 'kept', 'look super sleek skinny jeans'), (u'Priyanka Chopra', 'kept', 'look super sleek'), ('travels', 'kept', 'look super sleek jeans'), (u'Priyanka Chopra', 'kept navy boots', 'latest travels'), (u'Priyanka Chopra', 'kept coat', 'travels'), (u'Priyanka Chopra', 'travels', u'Priyanka Chopra'), ('latest travels', 'kept', 'look sleek jeans'), (u'Priyanka Chopra', 'kept navy boots at_time', 'travels'), (u'Priyanka Chopra', 'kept', 'look sleek jeans'), ('travels', 'kept', 'look super sleek'), (u'Priyanka Chopra', 'kept', 'look sleek skinny jeans'), ('travels', 'kept', 'cosy black'), ('latest travels', 'kept', 'look super sleek'), (u'Priyanka Chopra', 'kept', 'look super sleek skinny jeans'), ('latest travels', 'kept', 'look sleek skinny jeans'), ('travels', 'kept', 'black coat'), ('travels', 'kept', 'look sleek'), (u'Priyanka Chopra', 'kept', 'black'), ('latest travels', 'kept', 'navy boots'), (u'Priyanka Chopra', 'kept coat', 'latest travels'), ('latest travels', 'kept', 'black coat'), ('travels', 'kept', 'look sleek jeans'), (u'Priyanka Chopra', 'kept', 'cosy black'), ('latest travels', 'kept', 'look'), ('travels', 'kept', 'black'), ('travels', 'kept', 'look sleek skinny jeans'), (u'Priyanka Chopra', 'kept coat at_time', 'latest travels'), (u'Priyanka Chopra', 'kept', 'look sleek'), (u'Priyanka Chopra', 'kept', 'cosy black coat'), ('travels', 'kept', 'look'), (u'Priyanka Chopra', 'kept', 'coat'), ('latest travels', 'kept', 'look super sleek jeans'), ('travels', 'kept', 'navy blue boots'), (u'Priyanka Chopra', 'kept', 'cosy coat'), (u'Priyanka Chopra', 'kept navy boots', 'travels'), ('latest travels', 'kept', 'cosy coat'), ('travels', 'kept', 'cosy black coat'), ('travels', 'kept', 'navy boots'), (u'Priyanka Chopra', 'kept', 'look super sleek jeans'), ('travels', 'kept', 'look super sleek skinny jeans'), ('latest travels', 'kept', 'coat'), (u'Priyanka Chopra', 'kept', 'navy blue boots'), ('latest travels', 'kept', 'look sleek'), (u'Priyanka Chopra', 'kept', 'cosy'), (u'Priyanka Chopra', 'kept', 'look'), ('latest travels', 'kept', 'navy blue boots'), ('latest travels', 'kept', 'cosy black'), (u'Priyanka Chopra', 'kept coat at_time', 'travels'), ('travels', 'kept', 'cosy coat'), ('latest travels', 'kept', 'cosy black coat'), (u'Priyanka Chopra', 'kept', 'black coat')])\n",
      "NOUN PHRASES\n",
      "['latest travels', 'Priyanka Chopra', 'look', 'super sleek', 'skinny jeans', 'navy blue boots', 'cosy black coat']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'Priyanka Chopra', 'kept navy boots at_time', 'latest travels'), (u'Priyanka Chopra', 'kept', 'navy blue boots'), ('latest travels', 'kept', 'navy blue boots'), ('latest travels', 'kept', 'look'), (u'Priyanka Chopra', 'kept coat at_time', 'latest travels'), (u'Priyanka Chopra', 'kept', 'look'), (u'Priyanka Chopra', 'kept navy boots', 'latest travels'), (u'Priyanka Chopra', 'kept', 'cosy black coat'), (u'Priyanka Chopra', 'travels', u'Priyanka Chopra'), ('latest travels', 'kept', 'cosy black coat'), (u'Priyanka Chopra', 'kept coat', 'latest travels')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Just like Priyanka Chopra yesterday, Malaika Arora made her way to the UAE as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL RELATIONSHIPS\n",
      "set([('Priyanka Chopra', 'made', 'her way'), ('Chopra', 'made', 'her way'), ('Malaika Arora', 'made', 'her way')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Priyanka Chopra', u'Priyanka Chopra': u'Priyanka Chopra', u'Malaika Arora': u'Malaika Arora'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Priyanka Chopra', 'made', 'way'), ('Malaika Arora', 'made', 'way'), ('Chopra', 'made', 'way')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Priyanka Chopra', 'made', 'way'), (u'Malaika Arora', 'made', 'way'), ('Chopra', 'made', 'way')])\n",
      "NOUN PHRASES\n",
      "['Priyanka Chopra yesterday', 'Malaika Arora', 'way', 'UAE']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'Malaika Arora', 'made', 'way')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "The star left Mumbai last afternoon in a look similar to Chopras: perfectly tailored denims, ankle-length boots and oversized bag.\n",
      "ALL RELATIONSHIPS\n",
      "set([('star', 'left Mumbai at_time', 'last afternoon'), ('star', 'left Mumbai in', 'look similar to Chopras'), ('star', 'left Mumbai in', 'look'), ('star', 'left Mumbai in', 'look similar'), ('star', 'left Mumbai at_time', 'afternoon'), ('last afternoon', 'is in', 'look similar to Chopras'), ('star', 'left', 'Mumbai')])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('star', 'left Mumbai at_time', 'last afternoon'), ('star', 'left Mumbai', 'look similar Chopras'), ('star', 'left Mumbai', 'look similar'), ('last afternoon', 'is in', 'look similar Chopras'), ('star', 'left Mumbai at_time', 'afternoon'), ('star', 'left Mumbai', 'look'), ('star', 'left', 'Mumbai')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('star', 'left Mumbai at_time', 'last afternoon'), ('star', 'left Mumbai', 'look similar Chopras'), ('star', 'left Mumbai', 'look similar'), ('last afternoon', 'is in', 'look similar Chopras'), ('star', 'left Mumbai at_time', 'afternoon'), ('star', 'left Mumbai', 'look'), ('star', 'left', 'Mumbai')])\n",
      "NOUN PHRASES\n",
      "['star', 'Mumbai', 'last afternoon', 'look', 'denims', 'ankle-length boots', 'oversized bag']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('star', 'left Mumbai', 'look'), ('star', 'left Mumbai at_time', 'last afternoon'), ('star', 'left', 'Mumbai')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Instead of a warm jacket, Malaika Arora kept her look more casual with a white Balmain T-shirt.\n",
      "ALL RELATIONSHIPS\n",
      "set([('warm jacket', 'kept', 'her look more casual with white Balmain T-shirt'), ('Malaika Arora', 'kept', 'her look more casual with Balmain T-shirt'), ('her look', 'more casual with', 'a'), ('her look', 'more casual with', 'Balmain T-shirt'), ('Malaika Arora', 'kept', 'her look casual with white Balmain'), ('her look', 'casual with', 'white Balmain T-shirt'), ('her look', 'casual with', 'Balmain'), ('Malaika Arora', 'kept Instead of', 'jacket'), ('Malaika Arora', 'kept', 'her look casual with a'), ('her look', 'casual with', 'white Balmain'), ('warm jacket', 'kept', 'her look casual'), ('jacket', 'kept', 'her look more casual with Balmain'), ('warm jacket', 'kept', 'her look more casual with white Balmain'), ('her look', 'casual with', 'Balmain T-shirt'), ('warm jacket', 'kept', 'her look more casual with Balmain T-shirt'), ('her look', 'casual with', 'white'), ('jacket', 'kept', 'her look more casual with Balmain T-shirt'), ('Malaika Arora', 'kept Instead of', 'warm jacket'), ('warm jacket', 'kept', 'her look casual with Balmain'), ('Malaika Arora', 'kept', 'her look more casual with white'), ('Malaika Arora', 'kept', 'her look more casual with Balmain'), ('Malaika Arora', 'kept', 'her look casual with Balmain'), ('her look', 'casual with', 'a'), ('her look', 'more casual with', 'white Balmain T-shirt'), ('warm jacket', 'kept', 'her look casual with white Balmain T-shirt'), ('Malaika Arora', 'kept', 'her look casual'), ('Malaika Arora', 'kept', 'her look casual with Balmain T-shirt'), ('Malaika Arora', 'kept of', 'jacket'), ('her look', 'more casual with', 'white Balmain'), ('jacket', 'kept', 'her look casual with white Balmain'), ('jacket', 'kept', 'her look casual with white Balmain T-shirt'), ('Malaika Arora', 'kept', 'her look more casual with a'), ('jacket', 'kept', 'her look more casual with white Balmain'), ('Malaika Arora', 'kept', 'her look more casual'), ('warm jacket', 'kept', 'her look casual with white Balmain'), ('Malaika Arora', 'kept', 'her look more casual with white Balmain T-shirt'), ('Malaika Arora', 'kept', 'her look casual with white Balmain T-shirt'), ('jacket', 'kept', 'her look more casual'), ('her look', 'more casual with', 'Balmain'), ('Malaika Arora', 'kept', 'her look more casual with white Balmain'), ('Malaika Arora', 'kept at_time', 'jacket'), ('warm jacket', 'kept', 'her look casual with Balmain T-shirt'), ('jacket', 'kept', 'her look casual'), ('warm jacket', 'kept', 'her look more casual with Balmain'), ('jacket', 'kept', 'her look more casual with white Balmain T-shirt'), ('warm jacket', 'kept', 'her look more casual'), ('Malaika Arora', 'kept at_time', 'warm jacket'), ('jacket', 'kept', 'her look casual with Balmain T-shirt'), ('Malaika Arora', 'kept', 'her look casual with white'), ('jacket', 'kept', 'her look casual with Balmain'), ('her look', 'more casual with', 'white'), ('Malaika Arora', 'kept of', 'warm jacket')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Malaika Arora', u'Malaika Arora': u'Malaika Arora'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('look', 'casual', ''), ('Malaika Arora', 'kept', 'look casual'), ('warm jacket', 'kept', 'look casual white Balmain'), ('warm jacket', 'kept', 'look casual'), ('Malaika Arora', 'kept', 'warm jacket'), ('warm jacket', 'kept', 'look casual white Balmain T-shirt'), ('Malaika Arora', 'kept', 'look casual Balmain T-shirt'), ('look', 'casual', 'white Balmain'), ('look', 'casual', 'Balmain T-shirt'), ('look', 'casual', 'white'), ('look', 'casual', 'white Balmain T-shirt'), ('jacket', 'kept', 'look casual'), ('Malaika Arora', 'kept', 'look casual white'), ('warm jacket', 'kept', 'look casual Balmain'), ('jacket', 'kept', 'look casual Balmain T-shirt'), ('Malaika Arora', 'kept', 'look casual Balmain'), ('Malaika Arora', 'kept', 'look casual white Balmain T-shirt'), ('Malaika Arora', 'kept Instead', 'warm jacket'), ('jacket', 'kept', 'look casual Balmain'), ('warm jacket', 'kept', 'look casual Balmain T-shirt'), ('Malaika Arora', 'kept Instead', 'jacket'), ('Malaika Arora', 'kept', 'look casual white Balmain'), ('Malaika Arora', 'kept at_time', 'jacket'), ('look', 'casual', 'Balmain'), ('jacket', 'kept', 'look casual white Balmain'), ('Malaika Arora', 'kept at_time', 'warm jacket'), ('Malaika Arora', 'kept', 'jacket'), ('jacket', 'kept', 'look casual white Balmain T-shirt')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Malaika Arora', 'kept', 'look casual'), ('warm jacket', 'kept', 'look casual white Balmain'), ('warm jacket', 'kept', 'look casual'), (u'Malaika Arora', 'kept', 'warm jacket'), ('warm jacket', 'kept', 'look casual white Balmain T-shirt'), (u'Malaika Arora', 'kept', 'look casual Balmain T-shirt'), ('look', 'casual', 'white Balmain'), ('look', 'casual', 'Balmain T-shirt'), ('look', 'casual', 'white'), ('look', 'casual', 'white Balmain T-shirt'), ('jacket', 'kept', 'look casual'), (u'Malaika Arora', 'kept', 'look casual white'), ('warm jacket', 'kept', 'look casual Balmain'), ('jacket', 'kept', 'look casual Balmain T-shirt'), (u'Malaika Arora', 'kept', 'look casual Balmain'), (u'Malaika Arora', 'kept', 'look casual white Balmain T-shirt'), (u'Malaika Arora', 'kept Instead', 'warm jacket'), ('jacket', 'kept', 'look casual Balmain'), ('warm jacket', 'kept', 'look casual Balmain T-shirt'), (u'Malaika Arora', 'kept Instead', 'jacket'), (u'Malaika Arora', 'kept', 'look casual white Balmain'), (u'Malaika Arora', 'kept at_time', 'jacket'), ('look', 'casual', u'Malaika Arora'), ('look', 'casual', 'Balmain'), ('jacket', 'kept', 'look casual white Balmain'), (u'Malaika Arora', 'kept at_time', 'warm jacket'), (u'Malaika Arora', 'kept', 'jacket'), ('jacket', 'kept', 'look casual white Balmain T-shirt')])\n",
      "NOUN PHRASES\n",
      "['warm jacket', 'Malaika Arora', 'look', 'Balmain T-shirt']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('look', 'casual', u'Malaika Arora'), (u'Malaika Arora', 'kept at_time', 'warm jacket'), (u'Malaika Arora', 'kept Instead', 'warm jacket'), (u'Malaika Arora', 'kept', 'warm jacket'), ('look', 'casual', 'Balmain T-shirt')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Aditi Rao Hydari and Bella Hadids red carpet-ready looks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL RELATIONSHIPS\n",
      "set([])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([])\n",
      "NOUN PHRASES\n",
      "['Aditi Rao Hydari', 'Bella Hadids', 'carpet-ready looks']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "All this week, midnight blues have been a favourite with celebrities.\n",
      "ALL RELATIONSHIPS\n",
      "set([('midnight blues', 'have', 'have favourite with celebrities'), ('midnight blues', 'have', 'week have favourite with celebrities'), ('midnight blues', 'have', 'week have favourite'), ('midnight blues', 'have', 'week have a'), ('midnight blues', 'have', 'have favourite')])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('midnight blues', 'have', 'favourite'), ('midnight blues', 'have', 'week favourite celebrities'), ('midnight blues', 'have', 'week favourite'), ('midnight blues', 'have', 'week'), ('midnight blues', 'have', 'favourite celebrities')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('midnight blues', 'have', 'favourite'), ('midnight blues', 'have', 'favourite celebrities'), ('midnight blues', 'have', 'week favourite celebrities'), ('midnight blues', 'have', 'week'), ('midnight blues', 'have', 'week favourite')])\n",
      "NOUN PHRASES\n",
      "['week', 'midnight blues', 'favourite with celebrities']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('midnight blues', 'have', 'week'), ('midnight blues', 'have', 'favourite celebrities')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "After Kate Middleton and Meghan Markle stepped out together in navy dresses, Diana Penty made an appearance in a deep blue kurta set day before.\n",
      "ALL RELATIONSHIPS\n",
      "set([('Diana Penty', 'made appearance in', 'deep kurta set day'), ('Diana Penty', 'made appearance in', 'deep blue kurta day before'), ('Diana Penty', 'made', 'appearance'), ('Middleton', 'stepped out in', 'navy dresses'), ('Diana Penty', 'made appearance in', 'deep kurta day'), ('Diana Penty', 'made appearance in', 'deep blue kurta'), ('Diana Penty', 'made appearance in', 'blue kurta set'), ('Diana Penty', 'made appearance in', 'deep kurta set'), ('Diana Penty', 'made appearance in', 'kurta day before'), ('Diana Penty', 'made appearance in', 'kurta day'), ('Diana Penty', 'made appearance in', 'deep kurta'), ('Diana Penty', 'made appearance in', 'kurta set day'), ('Diana Penty', 'made appearance in', 'kurta set day before'), ('Diana Penty', 'made appearance in', 'kurta'), ('Kate Middleton', 'stepped out together in', 'navy dresses'), ('Diana Penty', 'made appearance in', 'blue kurta set day'), ('Diana Penty', 'made appearance in', 'deep kurta set day before'), ('Diana Penty', 'made appearance in', 'blue kurta set day before'), ('Meghan Markle', 'stepped out in', 'navy dresses'), ('Middleton', 'stepped out together in', 'navy dresses'), ('Diana Penty', 'made appearance in', 'blue kurta day before'), ('Diana Penty', 'made appearance in', 'deep blue kurta set'), ('Diana Penty', 'made appearance in', 'deep blue kurta day'), ('Diana Penty', 'made appearance in', 'deep blue kurta set day before'), ('Diana Penty', 'made appearance in', 'blue kurta day'), ('Diana Penty', 'made appearance in', 'blue kurta'), ('Diana Penty', 'made appearance in', 'deep blue kurta set day'), ('Diana Penty', 'made appearance in', 'kurta set'), ('Diana Penty', 'made appearance in', 'deep kurta day before'), ('Meghan Markle', 'stepped out together in', 'navy dresses'), ('Kate Middleton', 'stepped out in', 'navy dresses')])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Diana Penty', 'made appearance', 'deep kurta'), ('Diana Penty', 'made', 'appearance'), ('Kate Middleton', 'stepped', 'navy dresses'), ('Diana Penty', 'made appearance', 'deep blue kurta set day'), ('Diana Penty', 'made appearance', 'kurta'), ('Meghan Markle', 'stepped', 'navy dresses'), ('Diana Penty', 'made appearance', 'blue kurta day'), ('Diana Penty', 'made appearance', 'blue kurta set'), ('Diana Penty', 'made appearance', 'blue kurta'), ('Meghan Markle', 'stepped together', 'navy dresses'), ('Diana Penty', 'made appearance', 'deep blue kurta set'), ('Kate Middleton', 'stepped together', 'navy dresses'), ('Middleton', 'stepped together', 'navy dresses'), ('Diana Penty', 'made appearance', 'deep kurta set day'), ('Diana Penty', 'made appearance', 'kurta set'), ('Diana Penty', 'made appearance', 'deep kurta day'), ('Diana Penty', 'made appearance', 'kurta day'), ('Diana Penty', 'made appearance', 'kurta set day'), ('Diana Penty', 'made appearance', 'deep blue kurta'), ('Diana Penty', 'made appearance', 'blue kurta set day'), ('Diana Penty', 'made appearance', 'deep blue kurta day'), ('Diana Penty', 'made appearance', 'deep kurta set'), ('Middleton', 'stepped', 'navy dresses')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('Diana Penty', 'made appearance', 'deep kurta'), ('Diana Penty', 'made appearance', 'blue kurta'), ('Kate Middleton', 'stepped', 'navy dresses'), ('Diana Penty', 'made appearance', 'deep blue kurta set day'), ('Diana Penty', 'made appearance', 'kurta'), ('Meghan Markle', 'stepped', 'navy dresses'), ('Diana Penty', 'made appearance', 'blue kurta day'), ('Diana Penty', 'made appearance', 'deep kurta day'), ('Diana Penty', 'made', 'appearance'), ('Meghan Markle', 'stepped together', 'navy dresses'), ('Diana Penty', 'made appearance', 'deep blue kurta set'), ('Kate Middleton', 'stepped together', 'navy dresses'), ('Middleton', 'stepped together', 'navy dresses'), ('Diana Penty', 'made appearance', 'deep kurta set day'), ('Diana Penty', 'made appearance', 'kurta set'), ('Diana Penty', 'made appearance', 'blue kurta set'), ('Diana Penty', 'made appearance', 'kurta day'), ('Diana Penty', 'made appearance', 'kurta set day'), ('Diana Penty', 'made appearance', 'deep blue kurta'), ('Diana Penty', 'made appearance', 'blue kurta set day'), ('Diana Penty', 'made appearance', 'deep blue kurta day'), ('Diana Penty', 'made appearance', 'deep kurta set'), ('Middleton', 'stepped', 'navy dresses')])\n",
      "NOUN PHRASES\n",
      "['Kate Middleton', 'Meghan Markle', 'navy dresses', 'Diana Penty', 'appearance', 'blue kurta', 'day']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('Diana Penty', 'made appearance', 'blue kurta'), ('Diana Penty', 'made', 'appearance'), ('Kate Middleton', 'stepped', 'navy dresses'), ('Kate Middleton', 'stepped together', 'navy dresses'), ('Meghan Markle', 'stepped together', 'navy dresses'), ('Meghan Markle', 'stepped', 'navy dresses')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "And yesterday, Aditi Rao Hydari went with the classic hue for her evening out as well.\n",
      "ALL RELATIONSHIPS\n",
      "set([('Aditi Rao Hydari', 'went with', 'classic hue'), ('Rao Hydari', 'went for', 'her evening'), ('Aditi Rao Hydari', 'went for', 'her evening'), ('Aditi Rao Hydari', 'went at_time', 'yesterday'), ('Aditi Rao Hydari', 'went with', 'hue'), ('Rao Hydari', 'went with', 'hue'), ('Aditi Rao Hydari', 'went out with', 'hue'), ('Aditi Rao Hydari', 'went out for', 'her evening'), ('Rao Hydari', 'went with', 'classic hue'), ('Aditi Rao Hydari', 'went out with', 'classic hue'), ('Aditi Rao Hydari', 'went for', 'her evening out'), ('Aditi Rao Hydari', 'went out at_time', 'yesterday'), ('Rao Hydari', 'went for', 'her evening out')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Aditi Rao Hydari', u'Aditi Rao Hydari': u'Aditi Rao Hydari'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Aditi Rao Hydari', 'went at_time', 'yesterday'), ('Rao Hydari', 'went', 'hue'), ('Aditi Rao Hydari', 'went', 'hue'), ('Aditi Rao Hydari', 'went', 'classic hue'), ('Rao Hydari', 'went', 'evening'), ('Aditi Rao Hydari', 'went', 'evening'), ('Rao Hydari', 'went', 'classic hue')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Aditi Rao Hydari', 'went at_time', 'yesterday'), ('Rao Hydari', 'went', 'hue'), (u'Aditi Rao Hydari', 'went', 'hue'), (u'Aditi Rao Hydari', 'went', 'classic hue'), ('Rao Hydari', 'went', 'evening'), (u'Aditi Rao Hydari', 'went', 'evening'), ('Rao Hydari', 'went', 'classic hue')])\n",
      "NOUN PHRASES\n",
      "['yesterday', 'Aditi Rao Hydari', 'classic hue']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'Aditi Rao Hydari', 'went', 'classic hue'), (u'Aditi Rao Hydari', 'went at_time', 'yesterday')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "The actor headed out for the Times Retail Icon Awards in a velvet Aegean blue gown by Namrata Joshipura, completing her look with a sleek low ponytail and embellished choker.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL RELATIONSHIPS\n",
      "set([('Times Retail Icon Awards', 'is in', 'velvet Aegean blue gown by Namrata Joshipura'), ('actor', 'headed out in', 'velvet Aegean gown by Namrata Joshipura'), ('actor', 'completing', 'her look'), ('actor', 'completing', 'her look with low ponytail'), ('actor', 'headed out in', 'velvet Aegean blue gown by Namrata Joshipura'), ('actor', 'completing', 'her look with sleek ponytail'), ('actor', 'completing', 'her look with sleek low ponytail'), ('actor', 'completing', 'her look with ponytail'), ('actor', 'headed out in', 'velvet Aegean blue gown'), ('her look', 'is with', 'sleek low ponytail'), ('out Times Retail Icon Awards', 'is in', 'velvet Aegean blue gown by Namrata Joshipura'), ('actor', 'headed out for', 'Times Retail Icon Awards'), ('actor', 'headed out in', 'velvet Aegean gown')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Aditi Rao Hydari', u'actor': u'Aditi Rao Hydari'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('actor', 'headed', 'velvet Aegean blue gown Namrata Joshipura'), ('actor', 'headed', 'velvet Aegean gown Namrata Joshipura'), ('actor', 'completing', 'look low ponytail'), ('actor', 'completing', 'look ponytail'), ('actor', 'headed', 'Times Retail Icon Awards'), ('actor', 'headed', 'velvet Aegean blue gown'), ('actor', 'completing', 'look sleek low ponytail'), ('look', 'is with', 'sleek low ponytail'), ('actor', 'completing', 'look'), ('Times Retail Icon Awards', 'is in', 'velvet Aegean blue gown Namrata Joshipura'), ('actor', 'completing', 'look sleek ponytail'), ('actor', 'headed', 'velvet Aegean gown')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Aditi Rao Hydari', 'completing', 'look sleek ponytail'), (u'Aditi Rao Hydari', 'completing', 'look sleek low ponytail'), (u'Aditi Rao Hydari', 'completing', 'look ponytail'), (u'Aditi Rao Hydari', 'headed', 'velvet Aegean blue gown Namrata Joshipura'), ('look', 'is with', 'sleek low ponytail'), (u'Aditi Rao Hydari', 'completing', 'look low ponytail'), ('Times Retail Icon Awards', 'is in', 'velvet Aegean blue gown Namrata Joshipura'), (u'Aditi Rao Hydari', 'completing', 'look'), (u'Aditi Rao Hydari', 'headed', 'velvet Aegean gown'), (u'Aditi Rao Hydari', 'headed', 'Times Retail Icon Awards'), (u'Aditi Rao Hydari', 'headed', 'velvet Aegean gown Namrata Joshipura'), (u'Aditi Rao Hydari', 'headed', 'velvet Aegean blue gown')])\n",
      "NOUN PHRASES\n",
      "['actor', 'Times Retail Icon Awards', 'Aegean blue', 'Namrata Joshipura', 'look', 'sleek low ponytail', 'embellished choker']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'Aditi Rao Hydari', 'completing', 'look'), (u'Aditi Rao Hydari', 'headed', 'Times Retail Icon Awards'), ('look', 'is with', 'sleek low ponytail')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Overseas, Bella Hadid favoured dark blue too.\n",
      "ALL RELATIONSHIPS\n",
      "set([('Bella Hadid', 'Overseas favoured', 'dark blue'), ('Bella Hadid', 'favoured', 'dark'), ('Hadid', 'favoured', 'dark blue'), ('Hadid', 'favoured too', 'dark blue'), ('Bella Hadid', 'Overseas favoured', 'blue'), ('Bella Hadid', 'favoured', 'dark blue'), ('Bella Hadid', 'Overseas favoured too', 'blue'), ('Hadid', 'favoured', 'blue'), ('Hadid', 'favoured too', 'blue'), ('Bella Hadid', 'favoured too', 'blue'), ('Bella Hadid', 'favoured', 'blue'), ('Bella Hadid', 'favoured too', 'dark blue'), ('Bella Hadid', 'Overseas favoured too', 'dark blue'), ('Bella Hadid', 'Overseas favoured', 'dark')])\n",
      "COREF REPLACEMENTS\n",
      "{u'Bella Hadid': u'Bella Hadid'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Bella Hadid', 'favoured', 'dark'), ('Hadid', 'favoured', 'dark blue'), ('Bella Hadid', 'Overseas favoured', 'blue'), ('Bella Hadid', 'favoured', 'dark blue'), ('Hadid', 'favoured', 'blue'), ('Bella Hadid', 'Overseas favoured', 'dark blue'), ('Bella Hadid', 'favoured', 'blue'), ('Bella Hadid', 'Overseas favoured', 'dark')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'Bella Hadid', 'favoured', 'dark'), ('Hadid', 'favoured', 'dark blue'), (u'Bella Hadid', 'Overseas favoured', 'blue'), (u'Bella Hadid', 'favoured', 'dark blue'), ('Hadid', 'favoured', 'blue'), (u'Bella Hadid', 'Overseas favoured', 'dark blue'), (u'Bella Hadid', 'favoured', 'blue'), (u'Bella Hadid', 'Overseas favoured', 'dark')])\n",
      "NOUN PHRASES\n",
      "['Bella Hadid', 'dark blue']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'Bella Hadid', 'favoured', 'dark blue'), (u'Bella Hadid', 'Overseas favoured', 'dark blue')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "The model picked a Dior pantsuit in several shades of blue for her night out.\n",
      "ALL RELATIONSHIPS\n",
      "set([('model', 'picked Dior pantsuit in', 'shades'), ('model', 'picked Dior pantsuit in', 'shades of blue'), ('model', 'picked', 'Dior pantsuit'), ('model', 'picked Dior pantsuit in', 'several shades of blue'), ('model', 'picked Dior pantsuit for', 'her night out'), ('model', 'picked Dior pantsuit in', 'several shades'), ('model', 'picked Dior pantsuit for', 'her'), ('model', 'picked Dior pantsuit for', 'her night'), ('Dior pantsuit', 'is in', 'several shades of blue')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Bella Hadid'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('model', 'picked Dior pantsuit', 'shades blue'), ('model', 'picked Dior pantsuit', 'night'), ('model', 'picked Dior pantsuit', ''), ('model', 'picked', 'Dior pantsuit'), ('model', 'picked Dior pantsuit', 'several shades blue'), ('model', 'picked Dior pantsuit', 'several shades'), ('Dior pantsuit', 'is in', 'several shades blue'), ('model', 'picked Dior pantsuit', 'shades')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('model', 'picked Dior pantsuit', 'shades blue'), ('model', 'picked Dior pantsuit', 'night'), ('model', 'picked', 'Dior pantsuit'), ('model', 'picked Dior pantsuit', 'several shades blue'), ('model', 'picked Dior pantsuit', 'several shades'), ('Dior pantsuit', 'is in', 'several shades blue'), ('model', 'picked Dior pantsuit', u'Bella Hadid'), ('model', 'picked Dior pantsuit', 'shades')])\n",
      "NOUN PHRASES\n",
      "['model', 'Dior pantsuit', 'shades of blue', 'night']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('model', 'picked Dior pantsuit', 'shades blue'), ('model', 'picked Dior pantsuit', 'night'), ('model', 'picked', 'Dior pantsuit')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Kriti Sanon colour blocks with blue\n",
      "ALL RELATIONSHIPS\n",
      "set([('Kriti Sanon colour', 'blocks with', 'blue'), ('colour', 'blocks with', 'blue'), ('Sanon colour', 'blocks with', 'blue')])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('colour', 'blocks', 'blue'), ('Sanon colour', 'blocks', 'blue'), ('Kriti Sanon colour', 'blocks', 'blue')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('colour', 'blocks', 'blue'), ('Sanon colour', 'blocks', 'blue'), ('Kriti Sanon colour', 'blocks', 'blue')])\n",
      "NOUN PHRASES\n",
      "['Kriti Sanon colour blocks', 'blue']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Another star seen in blue yesterday was Kriti Sanon.\n",
      "ALL RELATIONSHIPS\n",
      "set([('Kriti', 'seen was at_time', 'yesterday'), ('yesterday Kriti Sanon', 'is in', 'blue'), ('star', 'seen in', 'blue'), ('seen yesterday', 'was', 'Kriti Sanon'), ('star', 'was', 'Kriti Sanon'), ('yesterday Kriti', 'is in', 'blue'), ('star', 'was', 'Kriti'), ('star', 'seen at_time', 'yesterday'), ('star yesterday', 'seen in', 'blue'), ('Kriti', 'seen was in', 'blue'), ('seen', 'was', 'Kriti Sanon')])\n",
      "COREF REPLACEMENTS\n",
      "{u'Kriti Sanon': u'Kriti Sanon'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('star yesterday', 'seen', 'blue'), ('yesterday Kriti', 'is in', 'blue'), ('Kriti', 'seen at_time', 'yesterday'), ('seen yesterday', 'was', 'Kriti Sanon'), ('star', 'was', 'Kriti Sanon'), ('yesterday Kriti Sanon', 'is in', 'blue'), ('Kriti', 'seen', 'blue'), ('star', 'was', 'Kriti'), ('star', 'seen at_time', 'yesterday'), ('star', 'seen', 'blue'), ('seen', 'was', 'Kriti Sanon')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('star yesterday', 'seen', 'blue'), ('yesterday Kriti Sanon', 'is in', 'blue'), ('Kriti', 'seen at_time', 'yesterday'), ('seen yesterday', 'was', u'Kriti Sanon'), ('star', 'was', u'Kriti Sanon'), ('yesterday Kriti', 'is in', 'blue'), ('Kriti', 'seen', 'blue'), ('star', 'was', 'Kriti'), ('star', 'seen at_time', 'yesterday'), ('star', 'seen', 'blue'), ('seen', 'was', u'Kriti Sanon')])\n",
      "NOUN PHRASES\n",
      "['star', 'blue yesterday', 'Kriti Sanon']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('star', 'was', u'Kriti Sanon')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "But while Aditi Rao Hydari and Bella Hadid picked darker tones of the colour, Kriti Sanon kept her look last afternoon breezy with a powder blue shirt, paired with a canary yellow tea skirt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL RELATIONSHIPS\n",
      "set([('Bella Hadid', 'darker tones of', 'colour'), ('Aditi Rao Hydari', 'picked', 'darker tones'), ('breezy', 'paired with', 'tea skirt'), ('Bella Hadid', 'picked', 'tones of colour'), ('Bella Hadid', 'picked', 'darker tones of colour'), ('Bella Hadid', 'tones of', 'colour'), ('her look', 'breezy with', 'powder blue shirt'), ('her look', 'breezy with', 'powder shirt'), ('Bella Hadid', 'tones of', 'Kriti Sanon'), ('breezy', 'paired with', 'yellow tea'), ('breezy', 'paired with', 'canary tea skirt'), ('breezy', 'paired with', 'canary yellow tea skirt'), ('Bella Hadid', 'darker tones of', 'Kriti Sanon'), ('breezy', 'paired with', 'canary yellow tea'), ('Aditi Rao Hydari', 'picked', 'tones'), ('Bella Hadid', 'picked', 'darker tones'), ('Aditi Rao Hydari', 'picked', 'tones of colour'), ('breezy', 'paired with', 'tea'), ('breezy', 'paired with', 'canary tea'), ('Aditi Rao Hydari', 'picked', 'darker tones of colour'), ('breezy', 'paired with', 'yellow tea skirt'), ('Bella Hadid', 'picked', 'tones')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Kriti Sanon', u'Kriti Sanon': u'Kriti Sanon'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Bella Hadid', 'darker tones', 'colour'), ('Aditi Rao Hydari', 'picked', 'darker tones colour'), ('look', 'breezy', 'powder blue shirt'), ('Aditi Rao Hydari', 'picked', 'darker tones'), ('look', 'breezy', 'powder shirt'), ('breezy', 'paired', 'tea skirt'), ('Bella Hadid', 'tones', 'colour'), ('breezy', 'paired', 'canary yellow tea skirt'), ('breezy', 'paired', 'yellow tea'), ('Bella Hadid', 'darker tones', 'Kriti Sanon'), ('breezy', 'paired', 'tea'), ('breezy', 'paired', 'canary yellow tea'), ('breezy', 'paired', 'canary tea'), ('Bella Hadid', 'tones', 'Kriti Sanon'), ('Bella Hadid', 'picked', 'tones colour'), ('Aditi Rao Hydari', 'picked', 'tones'), ('Bella Hadid', 'picked', 'darker tones'), ('Bella Hadid', 'picked', 'darker tones colour'), ('breezy', 'paired', 'canary tea skirt'), ('Aditi Rao Hydari', 'picked', 'tones colour'), ('Bella Hadid', 'picked', 'tones'), ('breezy', 'paired', 'yellow tea skirt')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('Bella Hadid', 'darker tones', 'colour'), ('Aditi Rao Hydari', 'picked', 'darker tones colour'), ('look', 'breezy', 'powder blue shirt'), ('Aditi Rao Hydari', 'picked', 'darker tones'), ('look', 'breezy', 'powder shirt'), ('breezy', 'paired', 'tea skirt'), ('Bella Hadid', 'tones', 'colour'), ('breezy', 'paired', 'canary yellow tea skirt'), ('breezy', 'paired', 'yellow tea'), ('Bella Hadid', 'darker tones', u'Kriti Sanon'), ('breezy', 'paired', 'tea'), ('breezy', 'paired', 'canary yellow tea'), ('breezy', 'paired', 'canary tea'), ('Bella Hadid', 'tones', u'Kriti Sanon'), ('Bella Hadid', 'picked', 'tones colour'), ('Aditi Rao Hydari', 'picked', 'tones'), ('Bella Hadid', 'picked', 'darker tones'), ('Bella Hadid', 'picked', 'darker tones colour'), ('breezy', 'paired', 'yellow tea skirt'), ('Aditi Rao Hydari', 'picked', 'tones colour'), ('Bella Hadid', 'picked', 'tones'), ('breezy', 'paired', 'canary tea skirt')])\n",
      "NOUN PHRASES\n",
      "['Aditi Rao Hydari', 'Bella Hadid', 'darker tones', 'colour', 'Kriti Sanon', 'look', 'afternoon breezy', 'powder blue shirt', 'tea skirt']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('Bella Hadid', 'darker tones', 'colour'), ('Bella Hadid', 'picked', 'darker tones'), ('look', 'breezy', 'powder blue shirt'), ('Aditi Rao Hydari', 'picked', 'darker tones'), ('Bella Hadid', 'tones', 'colour'), ('Bella Hadid', 'darker tones', u'Kriti Sanon'), ('Bella Hadid', 'tones', u'Kriti Sanon')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "The actor paired her cheery summer outfit with black kitten heels and a handful of minimal gold rings.\n",
      "ALL RELATIONSHIPS\n",
      "set([('actor', 'paired', 'her cheery summer outfit'), ('her cheery summer outfit', 'is with', 'black kitten heels'), ('actor', 'paired', 'her summer outfit'), ('outfit', 'is with', 'black kitten heels'), ('cheery summer outfit', 'is with', 'black kitten heels')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'The actor', u'actor': u'The actor'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('actor', 'paired', 'cheery summer outfit'), ('actor', 'paired', 'summer outfit'), ('outfit', 'is with', 'black kitten heels'), ('cheery summer outfit', 'is with', 'black kitten heels')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([(u'The actor', 'paired', 'summer outfit'), (u'The actor', 'paired', 'cheery summer outfit'), ('outfit', 'is with', 'black kitten heels'), ('cheery summer outfit', 'is with', 'black kitten heels')])\n",
      "NOUN PHRASES\n",
      "['actor', 'cheery summer outfit', 'kitten heels', 'handful', 'gold rings']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'The actor', 'paired', 'cheery summer outfit')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Lara Dutta Bhupathi goes the traditional route\n",
      "ALL RELATIONSHIPS\n",
      "set([('Dutta Bhupathi', 'goes', 'traditional'), ('Lara Dutta Bhupathi', 'goes', 'traditional route'), ('Bhupathi', 'goes', 'traditional route'), ('Dutta Bhupathi', 'goes', 'the'), ('Lara Dutta Bhupathi', 'goes', 'the'), ('Bhupathi', 'goes', 'traditional'), ('Lara Dutta Bhupathi', 'goes', 'traditional'), ('Dutta Bhupathi', 'goes', 'traditional route'), ('Dutta Bhupathi', 'goes', 'route'), ('Bhupathi', 'goes', 'route'), ('Lara Dutta Bhupathi', 'goes', 'route')])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('Dutta Bhupathi', 'goes', 'traditional'), ('Bhupathi', 'goes', 'traditional'), ('Lara Dutta Bhupathi', 'goes', ''), ('Bhupathi', 'goes', 'route'), ('Bhupathi', 'goes', 'traditional route'), ('Dutta Bhupathi', 'goes', ''), ('Lara Dutta Bhupathi', 'goes', 'traditional'), ('Dutta Bhupathi', 'goes', 'traditional route'), ('Lara Dutta Bhupathi', 'goes', 'traditional route'), ('Dutta Bhupathi', 'goes', 'route'), ('Lara Dutta Bhupathi', 'goes', 'route')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('Dutta Bhupathi', 'goes', 'traditional'), ('Dutta Bhupathi', 'goes', ''), ('Bhupathi', 'goes', 'traditional route'), ('Bhupathi', 'goes', 'route'), ('Lara Dutta Bhupathi', 'goes', 'route'), ('Bhupathi', 'goes', 'traditional'), ('Lara Dutta Bhupathi', 'goes', 'traditional'), ('Lara Dutta Bhupathi', 'goes', ''), ('Dutta Bhupathi', 'goes', 'traditional route'), ('Lara Dutta Bhupathi', 'goes', 'traditional route'), ('Dutta Bhupathi', 'goes', 'route')])\n",
      "NOUN PHRASES\n",
      "['Lara Dutta Bhupathi', 'traditional route']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('Lara Dutta Bhupathi', 'goes', 'traditional route')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Barely a day goes by in Bollywood without a star or two stepping out in an envy-worthy Indian ethnic ensemble.\n",
      "ALL RELATIONSHIPS\n",
      "set([('day', 'goes by', 'by Bollywood'), ('day', 'goes without', 'star')])\n",
      "COREF REPLACEMENTS\n",
      "{}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('day', 'goes without', 'star'), ('day', 'goes', 'Bollywood')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('day', 'goes without', 'star'), ('day', 'goes', 'Bollywood')])\n",
      "NOUN PHRASES\n",
      "['day', 'Bollywood', 'star', 'envy-worthy Indian ethnic ensemble']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('day', 'goes without', 'star'), ('day', 'goes', 'Bollywood')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "Last evening, it was Lara Dutta Bhupathi who had wedding hoppers talking about her latest OOTD.\n",
      "ALL RELATIONSHIPS\n",
      "set([])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Lara Dutta Bhupathi who had wedding hoppers talking about her latest OOTD', u'Lara Dutta Bhupathi wedding hoppers talking latest OOTD': u'Lara Dutta Bhupathi who had wedding hoppers talking about her latest OOTD'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([])\n",
      "NOUN PHRASES\n",
      "['Last evening', 'Lara Dutta Bhupathi', 'hoppers', 'latest OOTD']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "The actor, who is a judge on a reality dance show, picked an eye-catching black Shivan & Narresh sari for her day on set.\n",
      "ALL RELATIONSHIPS\n",
      "set([('judge', 'picked eye-catching black Shivan for', 'her day set'), ('judge', 'picked', 'Narresh sari'), ('judge', 'picked', 'eye-catching Shivan'), ('judge', 'picked', 'Shivan'), ('judge', 'picked Shivan for', 'her day'), ('judge', 'picked', 'eye-catching black Shivan'), ('judge', 'picked Narresh sari for', 'her day set'), ('judge', 'picked eye-catching Shivan for', 'her day set'), ('judge', 'picked black Shivan for', 'her day set'), ('judge', 'picked eye-catching Shivan for', 'her day'), ('judge', 'picked eye-catching black Shivan for', 'her day'), ('judge', 'picked Narresh sari for', 'her day'), ('judge', 'picked black Shivan for', 'her day'), ('judge', 'picked Shivan for', 'her day set'), ('judge', 'picked', 'black Shivan')])\n",
      "COREF REPLACEMENTS\n",
      "{'': u'Lara Dutta Bhupathi who had wedding hoppers talking about her latest OOTD'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('judge', 'picked', 'Narresh sari'), ('judge', 'picked eye-catching Shivan', 'day set'), ('judge', 'picked Narresh sari', 'day set'), ('judge', 'picked black Shivan', 'day set'), ('judge', 'picked', 'eye-catching Shivan'), ('judge', 'picked eye-catching Shivan', 'day'), ('judge', 'picked Narresh sari', 'day'), ('judge', 'picked', 'Shivan'), ('judge', 'picked black Shivan', 'day'), ('judge', 'picked Shivan', 'day set'), ('judge', 'picked', 'eye-catching black Shivan'), ('judge', 'picked eye-catching black Shivan', 'day'), ('judge', 'picked Shivan', 'day'), ('judge', 'picked eye-catching black Shivan', 'day set'), ('judge', 'picked', 'black Shivan')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('judge', 'picked', 'Narresh sari'), ('judge', 'picked eye-catching Shivan', 'day set'), ('judge', 'picked Narresh sari', 'day set'), ('judge', 'picked black Shivan', 'day set'), ('judge', 'picked', 'eye-catching Shivan'), ('judge', 'picked eye-catching Shivan', 'day'), ('judge', 'picked Narresh sari', 'day'), ('judge', 'picked', 'Shivan'), ('judge', 'picked black Shivan', 'day'), ('judge', 'picked Shivan', 'day set'), ('judge', 'picked', 'eye-catching black Shivan'), ('judge', 'picked eye-catching black Shivan', 'day'), ('judge', 'picked Shivan', 'day'), ('judge', 'picked eye-catching black Shivan', 'day set'), ('judge', 'picked', 'black Shivan')])\n",
      "NOUN PHRASES\n",
      "['actor', 'judge', 'reality dance show', 'eye-catching black Shivan', 'Narresh sari', 'day on set']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([('judge', 'picked', 'Narresh sari'), ('judge', 'picked eye-catching Shivan', 'day set'), ('judge', 'picked Narresh sari', 'day set'), ('judge', 'picked black Shivan', 'day set'), ('judge', 'picked Shivan', 'day set'), ('judge', 'picked', 'eye-catching black Shivan'), ('judge', 'picked eye-catching black Shivan', 'day set')])\n",
      "-----------------------------\n",
      "SENTENCE\n",
      "If you love intense embellishment, busy, vibrant florals and unique cuts, this sari is your perfect match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL RELATIONSHIPS\n",
      "set([('you', 'love', 'vibrant florals'), ('sari', 'is', 'your perfect'), ('sari', 'is', 'your match'), ('you', 'love', 'florals'), ('sari', 'is', 'your perfect match'), ('you', 'love', 'embellishment busy'), ('you', 'love', 'intense embellishment'), ('you', 'love', 'embellishment'), ('you', 'love', 'unique cuts'), ('you', 'love', 'intense embellishment busy'), ('you', 'love', 'cuts')])\n",
      "COREF REPLACEMENTS\n",
      "{u'sari': u'an eye-catching black Shivan & Narresh sari for her day on set'}\n",
      "RELATIONSHIPS AFTER REMOVING STOPWORDS\n",
      "set([('', 'love', 'embellishment'), ('', 'love', 'embellishment busy'), ('', 'love', 'florals'), ('', 'love', 'cuts'), ('', 'love', 'intense embellishment'), ('', 'love', 'intense embellishment busy'), ('sari', 'is', 'perfect match'), ('', 'love', 'unique cuts'), ('', 'love', 'vibrant florals'), ('sari', 'is', 'perfect'), ('sari', 'is', 'match')])\n",
      "RELATIONSHIPS AFTER CoREF REPLACEMENT\n",
      "set([('', 'love', 'embellishment'), ('', 'love', 'embellishment busy'), ('', 'love', 'florals'), ('', 'love', 'cuts'), ('', 'love', 'intense embellishment'), ('', 'love', 'intense embellishment busy'), (u'an eye-catching black Shivan & Narresh sari for her day on set', 'is', 'perfect match'), ('', 'love', 'unique cuts'), ('', 'love', 'vibrant florals'), (u'an eye-catching black Shivan & Narresh sari for her day on set', 'is', 'perfect'), (u'an eye-catching black Shivan & Narresh sari for her day on set', 'is', 'match')])\n",
      "NOUN PHRASES\n",
      "['intense embellishment', 'vibrant florals', 'unique cuts', 'sari', 'perfect match']\n",
      "RELATIONSHIPS AFTER NOUN PHRASE FIltering\n",
      "set([(u'an eye-catching black Shivan & Narresh sari for her day on set', 'is', 'perfect match')])\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "db = MySQLdb.connect(host=\"localhost\",    # your host, usually localhost\n",
    "                     user=\"root\",         # your username\n",
    "                     passwd=\"foobar\",  # your password\n",
    "                     db=\"new_trends\")        # name of the data base\n",
    "\n",
    "cur = db.cursor()\n",
    "\n",
    "# Use all the SQL you like\n",
    "cur.execute(\"SELECT * FROM TEXTS WHERE SOURCE = 'DIFFBOT' and type = 'BODY' and id =93\")\n",
    "\n",
    "# print all the first cell of all the rows\n",
    "for row in cur.fetchall():\n",
    "    if row[1]:\n",
    "        lines = line_splitter(row[1])\n",
    "        for line in lines:\n",
    "            prcoess_relations(line)\n",
    "        print \"********************************************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After Kate Middleton and Meghan Markle stepped out together in navy dresses, Diana Penty made an appearance in a deep blue kurta set day before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
